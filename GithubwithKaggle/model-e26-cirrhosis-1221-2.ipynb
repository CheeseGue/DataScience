{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef4ede6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-21T13:50:26.205230Z",
     "iopub.status.busy": "2023-12-21T13:50:26.204865Z",
     "iopub.status.idle": "2023-12-21T13:50:27.102060Z",
     "shell.execute_reply": "2023-12-21T13:50:27.100520Z"
    },
    "papermill": {
     "duration": 0.907262,
     "end_time": "2023-12-21T13:50:27.104713",
     "exception": false,
     "start_time": "2023-12-21T13:50:26.197451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/playground-series-s3e26/sample_submission.csv\n",
      "/kaggle/input/playground-series-s3e26/train.csv\n",
      "/kaggle/input/playground-series-s3e26/test.csv\n",
      "/kaggle/input/cirrhosis-patient-survival-prediction/cirrhosis.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c5af9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:50:27.119788Z",
     "iopub.status.busy": "2023-12-21T13:50:27.119203Z",
     "iopub.status.idle": "2023-12-21T13:50:30.912193Z",
     "shell.execute_reply": "2023-12-21T13:50:30.911278Z"
    },
    "papermill": {
     "duration": 3.802814,
     "end_time": "2023-12-21T13:50:30.914791",
     "exception": false,
     "start_time": "2023-12-21T13:50:27.111977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import log_loss,make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa53df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:50:30.927834Z",
     "iopub.status.busy": "2023-12-21T13:50:30.927194Z",
     "iopub.status.idle": "2023-12-21T13:50:31.803522Z",
     "shell.execute_reply": "2023-12-21T13:50:31.802348Z"
    },
    "papermill": {
     "duration": 0.885904,
     "end_time": "2023-12-21T13:50:31.806028",
     "exception": false,
     "start_time": "2023-12-21T13:50:30.920124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "読み込み完了 /kaggle/working/data.csv\n"
     ]
    }
   ],
   "source": [
    "# ライブラリ・データセットのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## 実行時間を調べるために使う\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def changeHMS(s):\n",
    "    h = math.floor(s / 3600)\n",
    "    if h > 0:\n",
    "        s = s - h * 3600\n",
    "        indi_h = str(h) + 'h'\n",
    "    else:\n",
    "        indi_h = ''\n",
    "    m = math.floor(s / 60)\n",
    "    if m > 0:\n",
    "        indi_m = str(m) + 'm'\n",
    "    else:\n",
    "        indi_m = ''\n",
    "    s = math.floor(s % 60)\n",
    "    time = indi_h + indi_m + str(s) + 's'\n",
    "    return time\n",
    "\n",
    "FILE_PATH = '/kaggle/input/playground-series-s3e26/'\n",
    "OUTPUT_DIR = '/kaggle/working/'\n",
    "\n",
    "train = pd.read_csv(FILE_PATH + 'train.csv')\n",
    "test = pd.read_csv(FILE_PATH + 'test.csv')\n",
    "\n",
    "test_id = test['id']\n",
    "\n",
    "target = train['Status']\n",
    "\n",
    "target_name = str(train.iloc[:, [18]].columns.tolist()) # カラム数-2の値が目的変数\n",
    "\n",
    "df = pd.concat([train, test], axis=0)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# 説明変数をデータ型ごとに代入する\n",
    "numerical_features = df._get_numeric_data().columns\n",
    "categorical_features = df.drop(numerical_features, axis=1).columns\n",
    "numerical_features = numerical_features.drop('id')\n",
    "\n",
    "# 前処理\n",
    "# 欠損値の補完\n",
    "def missing_values(df):\n",
    "\n",
    "    return df\n",
    "\n",
    "# 外れ値の削除\n",
    "def outlier(df):\n",
    "\n",
    "    return df\n",
    "\n",
    "# MinMaxScaler(正規化)\n",
    "def scaling(df):\n",
    "    df_scale = df[numerical_features]\n",
    "    sc = MinMaxScaler()\n",
    "    df[numerical_features] = pd.DataFrame(sc.fit_transform(df_scale), columns = df_scale.columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "# 特徴量エンジニアリング\n",
    "# 特徴量の作成\n",
    "def create_new_features(df):\n",
    "    # 血小板減少症インジケーター\n",
    "    threshold_platelets = 150 # 閾値\n",
    "    df['thrombocytopenia'] = np.where(df['Platelets'] < threshold_platelets, 1, 0)\n",
    "\n",
    "    # アルカリ性リン酸塩ホスファターゼの上昇指標：\n",
    "    threshold_alk_phos_upper = 147\n",
    "    threshold_alk_phos_lower = 44\n",
    "    df['elevated_alk_phos'] = np.where((df['Alk_Phos'] > threshold_alk_phos_upper) | (df['Alk_Phos'] < threshold_alk_phos_lower), 1, 0)\n",
    "\n",
    "    # 正常な銅レベル\n",
    "    normal_copper_range = (62, 140)\n",
    "    df['normal_copper'] = np.where((df['Copper'] >= normal_copper_range[0]) & (df['Copper'] <= normal_copper_range[1]), 1, 0)\n",
    "\n",
    "    # アルブミンの正常範囲\n",
    "    normal_albumin_range = (3.4, 5.4)\n",
    "    df['normal_albumin'] = np.where((df['Albumin'] >= normal_albumin_range[1]), 1, 0)\n",
    "\n",
    "    # 正常なビリルビンレベル\n",
    "    normal_bilirubin_range = (0.2, 1.2)\n",
    "    df['normal_bilirubin'] = np.where((df['Bilirubin'] >= normal_bilirubin_range[0]) & (df['Bilirubin'] <= normal_bilirubin_range[1]), 1, 0)\n",
    "\n",
    "    # 診断日\n",
    "    df['DiagnosisDays'] = df['Age'] - df['N_Days']\n",
    "\n",
    "    # ビリルビン * アルブミン\n",
    "    df['Bilirubin_Albumin'] = df['Bilirubin'] * df['Albumin']\n",
    "\n",
    "    # 症状のスコア\n",
    "    symptom_columns = ['Ascites', 'Hepatomegaly', 'Spiders']\n",
    "    df['Symptom_Score'] = df[symptom_columns].sum(axis=1)\n",
    "\n",
    "    # 肝臓機能\n",
    "    liver_columns = ['Bilirubin', 'Albumin', 'Alk_Phos', 'SGOT']\n",
    "    df['Liver_Function_Index'] = df[liver_columns].mean(axis=1)\n",
    "\n",
    "    # リスクスコア\n",
    "    df['Risk_Score'] = df['Bilirubin'] + df['Albumin'] - df['Alk_Phos']\n",
    "\n",
    "    # 時間特徴量\n",
    "    df['Diag_Year'] = (df['N_Days'] / 365).astype(int)\n",
    "    df['Diag_Month'] = ((df['N_Days'] % 365) / 30).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "# 年齢に関する特徴量の追加\n",
    "def convert_days_to_years(age_in_days):\n",
    "    days_in_year = 365.25\n",
    "    age_in_years = age_in_days / days_in_year\n",
    "\n",
    "    return age_in_years\n",
    "\n",
    "def add_cols(df):\n",
    "    age = list(df.Age)\n",
    "    age_in_year = []\n",
    "    for i in age:\n",
    "        age_in_year.append(int(convert_days_to_years(i)))\n",
    "    df['Age_in_year'] = pd.Series(age_in_year)\n",
    "\n",
    "    return df\n",
    "\n",
    "# カテゴリ変数のエンコーディング\n",
    "# One-Hot Encoding\n",
    "def one_hot_encoding(df, cat_cols):\n",
    "    df = pd.get_dummies(df, columns=cat_cols)\n",
    "    # 目的変数を数値化(int64)する\n",
    "    df['Status'] = df['Status'].map({\"D\": 0, \"CL\": 1, \"C\": 2})\n",
    "    # 一緒にラベルエンコーディングすると、1,2,3になってしまいモデル学習できないため分割する\n",
    "\n",
    "    return df\n",
    "\n",
    "# LabelEncoding\n",
    "def label_encoder(df):\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].fillna('').astype('str') # 欠損値の補完をする\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "    return df\n",
    "\n",
    "# 特徴量の選択\n",
    "# 特徴量の重要度評価\n",
    "def feature_importance_evaluation(df):\n",
    "    # データを対数変換する\n",
    "\n",
    "    # 訓練データをX(説明変数)とy（目的変数）に分割する\n",
    "    X = df.select_dtypes(include=['float', 'int'])\n",
    "    X = X.drop(['Status'], axis=1) # 目的変数を指定する\n",
    "    y = target # 目的変数を指定する\n",
    "\n",
    "    for column in X.columns.tolist():\n",
    "        X[column] = X[column].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "    # 特徴量の重要度評価\n",
    "    lgb = LGBMClassifier(\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    lgb.fit(X, y)\n",
    "    importance = lgb.feature_importances_\n",
    "\n",
    "    feature_importance = pd.DataFrame(data=importance, index=X.columns, columns=['importance']) \\\n",
    "        .sort_values(ascending=True, by='importance')\n",
    "\n",
    "    return feature_importance\n",
    "\n",
    "# 特徴量の削除\n",
    "def drop_columns(df):\n",
    "    drop_list = [\n",
    "        'index'\n",
    "    ]\n",
    "    dropped_df = df.drop(columns=drop_list)\n",
    "\n",
    "    return dropped_df\n",
    "\n",
    "# データセットの更新\n",
    "# 前処理\n",
    "df = add_cols(df)\n",
    "df = missing_values(df)\n",
    "df = outlier(df)\n",
    "# df = scaling(df) # 標準化したい時のみ実行する\n",
    "\n",
    "# 特徴量エンジニアリング\n",
    "df = create_new_features(df)\n",
    "df = drop_columns(df)\n",
    "\n",
    "cat_cols = ['Edema', 'Stage'] # One-Hot Encodingしたい水準数の少ないカラムを指定する\n",
    "df = one_hot_encoding(df, cat_cols)\n",
    "df = label_encoder(df)\n",
    "\n",
    "train = df[df.loc[:, 'id'] < 7905]\n",
    "test = df[df.loc[:, 'id'] >= 7905]\n",
    "\n",
    "train_x = train.drop(columns=['Status', 'id'])\n",
    "train_y = target\n",
    "test_x = test.drop(columns=['Status', 'id'])\n",
    "\n",
    "X = train_x.values\n",
    "y = train_y.values\n",
    "# y = y.astype(int)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# ID削除\n",
    "df.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "df.to_csv(OUTPUT_DIR + 'data.csv', index=False)\n",
    "\n",
    "# 確認 (data_import.py)\n",
    "def file_to_xy(filename):\n",
    "    data = pd.read_csv(filename, index_col=0)\n",
    "    print(f'読み込み完了 {filename}')\n",
    "    train = data[:7905].reset_index(drop=True)\n",
    "    test = data[7905:].reset_index(drop=True).drop('Status', axis=1)\n",
    "    # 目的変数と説明変数に分割\n",
    "    X = train.drop('Status', axis=1)\n",
    "    y = train['Status'].values\n",
    "    return data,test,train,X,y\n",
    "\n",
    "filename = OUTPUT_DIR + 'data.csv'\n",
    "data,test,train,X,y = file_to_xy(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816966b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:50:31.818434Z",
     "iopub.status.busy": "2023-12-21T13:50:31.818019Z",
     "iopub.status.idle": "2023-12-21T13:50:31.827175Z",
     "shell.execute_reply": "2023-12-21T13:50:31.826135Z"
    },
    "papermill": {
     "duration": 0.018255,
     "end_time": "2023-12-21T13:50:31.829668",
     "exception": false,
     "start_time": "2023-12-21T13:50:31.811413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ad9ebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:50:31.842117Z",
     "iopub.status.busy": "2023-12-21T13:50:31.841762Z",
     "iopub.status.idle": "2023-12-21T13:50:31.852629Z",
     "shell.execute_reply": "2023-12-21T13:50:31.851458Z"
    },
    "papermill": {
     "duration": 0.0201,
     "end_time": "2023-12-21T13:50:31.855133",
     "exception": false,
     "start_time": "2023-12-21T13:50:31.835033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_columns = df.select_dtypes(exclude=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a22512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:50:31.867248Z",
     "iopub.status.busy": "2023-12-21T13:50:31.866851Z",
     "iopub.status.idle": "2023-12-21T13:50:50.363803Z",
     "shell.execute_reply": "2023-12-21T13:50:50.362328Z"
    },
    "papermill": {
     "duration": 18.506033,
     "end_time": "2023-12-21T13:50:50.366526",
     "exception": false,
     "start_time": "2023-12-21T13:50:31.860493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss - CatBoost: 0.4592786069304633\n",
      "Log Loss - Gradient_Boosting: 0.4417445827289941\n",
      "Log Loss - LightGBM: 0.49196989587726075\n",
      "Log Loss - Ensemble: 0.4402829831313499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "cat_feature_indices = [df.columns.get_loc(col) for col in categorical_columns]\n",
    "cat_columns= categorical_columns[:-1]\n",
    "models = [\n",
    "    ('CatBoost', CatBoostClassifier(iterations=300, random_seed=42, logging_level='Silent', cat_features=cat_columns)),\n",
    "    ('Gradient_Boosting', GradientBoostingClassifier(n_estimators=150, random_state=42)),\n",
    "    ('LightGBM',   LGBMClassifier(n_estimators=150, random_state=42, categorical_feature=cat_feature_indices))\n",
    "]\n",
    "\n",
    "sum_prediction=0\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict_proba(X_test)\n",
    "    sum_prediction= predictions + sum_prediction\n",
    "    loss = log_loss(y_test, predictions)\n",
    "    print(f'Log Loss - {model_name}: {loss}')\n",
    "    \n",
    "Ensemble_pred= sum_prediction/5\n",
    "Ensemble_logloss= log_loss(y_test, Ensemble_pred)\n",
    "print(f'Log Loss - Ensemble: {Ensemble_logloss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97541826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:50:50.379574Z",
     "iopub.status.busy": "2023-12-21T13:50:50.379157Z",
     "iopub.status.idle": "2023-12-21T13:50:50.385175Z",
     "shell.execute_reply": "2023-12-21T13:50:50.384203Z"
    },
    "papermill": {
     "duration": 0.015083,
     "end_time": "2023-12-21T13:50:50.387390",
     "exception": false,
     "start_time": "2023-12-21T13:50:50.372307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df= test.copy()\n",
    "# test_df['Age'] = test_df['Age'] // 365.25\n",
    "# test_df['N_Days'] = test_df['N_Days'] // 365.25\n",
    "# test_df.rename(columns={'N_Days': 'N_years'}, inplace=True)\n",
    "for colum in cat_columns:\n",
    "    test_df[colum]=le.fit_transform(test_df[colum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4776f166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:50:50.400559Z",
     "iopub.status.busy": "2023-12-21T13:50:50.399730Z",
     "iopub.status.idle": "2023-12-21T13:51:10.884991Z",
     "shell.execute_reply": "2023-12-21T13:51:10.884025Z"
    },
    "papermill": {
     "duration": 20.494681,
     "end_time": "2023-12-21T13:51:10.887647",
     "exception": false,
     "start_time": "2023-12-21T13:50:50.392966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X.copy()\n",
    "y_train = y.copy()\n",
    "X_test = test_df  \n",
    "\n",
    "sum_predictions=0\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict_proba(X_test)\n",
    "    sum_predictions=sum_predictions+predictions\n",
    "\n",
    "ensemble_predictions = sum_predictions/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637fb708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:51:10.900931Z",
     "iopub.status.busy": "2023-12-21T13:51:10.900570Z",
     "iopub.status.idle": "2023-12-21T13:51:10.908488Z",
     "shell.execute_reply": "2023-12-21T13:51:10.907479Z"
    },
    "papermill": {
     "duration": 0.01715,
     "end_time": "2023-12-21T13:51:10.910829",
     "exception": false,
     "start_time": "2023-12-21T13:51:10.893679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39756985, 0.01914351, 0.58328664],\n",
       "       [0.18717854, 0.14815842, 0.66466304],\n",
       "       [0.96105437, 0.01347337, 0.02547226],\n",
       "       ...,\n",
       "       [0.04392351, 0.00387841, 0.95219809],\n",
       "       [0.00695053, 0.00391933, 0.98913014],\n",
       "       [0.6902713 , 0.01205439, 0.29767431]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee3d5fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:51:10.924521Z",
     "iopub.status.busy": "2023-12-21T13:51:10.924148Z",
     "iopub.status.idle": "2023-12-21T13:51:10.944179Z",
     "shell.execute_reply": "2023-12-21T13:51:10.943070Z"
    },
    "papermill": {
     "duration": 0.029891,
     "end_time": "2023-12-21T13:51:10.946559",
     "exception": false,
     "start_time": "2023-12-21T13:51:10.916668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Status_C</th>\n",
       "      <th>Status_CL</th>\n",
       "      <th>Status_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7905</td>\n",
       "      <td>0.397570</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>0.583287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7906</td>\n",
       "      <td>0.187179</td>\n",
       "      <td>0.148158</td>\n",
       "      <td>0.664663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7907</td>\n",
       "      <td>0.961054</td>\n",
       "      <td>0.013473</td>\n",
       "      <td>0.025472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7908</td>\n",
       "      <td>0.044338</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.953399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7909</td>\n",
       "      <td>0.107533</td>\n",
       "      <td>0.019644</td>\n",
       "      <td>0.872823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>13171</td>\n",
       "      <td>0.034039</td>\n",
       "      <td>0.032474</td>\n",
       "      <td>0.933486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>13172</td>\n",
       "      <td>0.019761</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.978341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>13173</td>\n",
       "      <td>0.043924</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.952198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>13174</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.989130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>13175</td>\n",
       "      <td>0.690271</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.297674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5271 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  Status_C  Status_CL  Status_D\n",
       "0      7905  0.397570   0.019144  0.583287\n",
       "1      7906  0.187179   0.148158  0.664663\n",
       "2      7907  0.961054   0.013473  0.025472\n",
       "3      7908  0.044338   0.002263  0.953399\n",
       "4      7909  0.107533   0.019644  0.872823\n",
       "...     ...       ...        ...       ...\n",
       "5266  13171  0.034039   0.032474  0.933486\n",
       "5267  13172  0.019761   0.001898  0.978341\n",
       "5268  13173  0.043924   0.003878  0.952198\n",
       "5269  13174  0.006951   0.003919  0.989130\n",
       "5270  13175  0.690271   0.012054  0.297674\n",
       "\n",
       "[5271 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'id': test_id,\n",
    "    'Status_C': ensemble_predictions[:, 0],\n",
    "    'Status_CL': ensemble_predictions[:, 1],\n",
    "    'Status_D': ensemble_predictions[:, 2]\n",
    "})\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b4f4b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:51:10.960962Z",
     "iopub.status.busy": "2023-12-21T13:51:10.960596Z",
     "iopub.status.idle": "2023-12-21T13:51:11.016188Z",
     "shell.execute_reply": "2023-12-21T13:51:11.015125Z"
    },
    "papermill": {
     "duration": 0.066099,
     "end_time": "2023-12-21T13:51:11.019014",
     "exception": false,
     "start_time": "2023-12-21T13:51:10.952915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a5d04",
   "metadata": {
    "papermill": {
     "duration": 0.005814,
     "end_time": "2023-12-21T13:51:11.031191",
     "exception": false,
     "start_time": "2023-12-21T13:51:11.025377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7000181,
     "sourceId": 60893,
     "sourceType": "competition"
    },
    {
     "datasetId": 3873965,
     "sourceId": 6724823,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.388933,
   "end_time": "2023-12-21T13:51:11.861419",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-21T13:50:22.472486",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
