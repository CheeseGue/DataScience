{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560504fc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:14.022975Z",
     "iopub.status.busy": "2023-12-21T13:54:14.022536Z",
     "iopub.status.idle": "2023-12-21T13:54:14.956759Z",
     "shell.execute_reply": "2023-12-21T13:54:14.955174Z"
    },
    "papermill": {
     "duration": 0.946152,
     "end_time": "2023-12-21T13:54:14.960337",
     "exception": false,
     "start_time": "2023-12-21T13:54:14.014185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cirrhosis-patient-survival-prediction/cirrhosis.csv\n",
      "/kaggle/input/playground-series-s3e26/sample_submission.csv\n",
      "/kaggle/input/playground-series-s3e26/train.csv\n",
      "/kaggle/input/playground-series-s3e26/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d011fd20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:14.976225Z",
     "iopub.status.busy": "2023-12-21T13:54:14.975647Z",
     "iopub.status.idle": "2023-12-21T13:54:18.931712Z",
     "shell.execute_reply": "2023-12-21T13:54:18.930289Z"
    },
    "papermill": {
     "duration": 3.966108,
     "end_time": "2023-12-21T13:54:18.934711",
     "exception": false,
     "start_time": "2023-12-21T13:54:14.968603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import log_loss,make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1107d824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:18.948292Z",
     "iopub.status.busy": "2023-12-21T13:54:18.947835Z",
     "iopub.status.idle": "2023-12-21T13:54:19.836332Z",
     "shell.execute_reply": "2023-12-21T13:54:19.834645Z"
    },
    "papermill": {
     "duration": 0.898878,
     "end_time": "2023-12-21T13:54:19.839151",
     "exception": false,
     "start_time": "2023-12-21T13:54:18.940273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "読み込み完了 /kaggle/working/data.csv\n"
     ]
    }
   ],
   "source": [
    "# ライブラリ・データセットのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## 実行時間を調べるために使う\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def changeHMS(s):\n",
    "    h = math.floor(s / 3600)\n",
    "    if h > 0:\n",
    "        s = s - h * 3600\n",
    "        indi_h = str(h) + 'h'\n",
    "    else:\n",
    "        indi_h = ''\n",
    "    m = math.floor(s / 60)\n",
    "    if m > 0:\n",
    "        indi_m = str(m) + 'm'\n",
    "    else:\n",
    "        indi_m = ''\n",
    "    s = math.floor(s % 60)\n",
    "    time = indi_h + indi_m + str(s) + 's'\n",
    "    return time\n",
    "\n",
    "FILE_PATH = '/kaggle/input/playground-series-s3e26/'\n",
    "OUTPUT_DIR = '/kaggle/working/'\n",
    "\n",
    "train = pd.read_csv(FILE_PATH + 'train.csv')\n",
    "test = pd.read_csv(FILE_PATH + 'test.csv')\n",
    "\n",
    "test_id = test['id']\n",
    "\n",
    "target = train['Status']\n",
    "\n",
    "target_name = str(train.iloc[:, [18]].columns.tolist()) # カラム数-2の値が目的変数\n",
    "\n",
    "df = pd.concat([train, test], axis=0)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# 説明変数をデータ型ごとに代入する\n",
    "numerical_features = df._get_numeric_data().columns\n",
    "categorical_features = df.drop(numerical_features, axis=1).columns\n",
    "numerical_features = numerical_features.drop('id')\n",
    "\n",
    "# 前処理\n",
    "# 欠損値の補完\n",
    "def missing_values(df):\n",
    "\n",
    "    return df\n",
    "\n",
    "# 外れ値の削除\n",
    "def outlier(df):\n",
    "\n",
    "    return df\n",
    "\n",
    "# MinMaxScaler(正規化)\n",
    "def scaling(df):\n",
    "    df_scale = df[numerical_features]\n",
    "    sc = MinMaxScaler()\n",
    "    df[numerical_features] = pd.DataFrame(sc.fit_transform(df_scale), columns = df_scale.columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "# 特徴量エンジニアリング\n",
    "# 特徴量の作成\n",
    "def create_new_features(df):\n",
    "    # 血小板減少症インジケーター\n",
    "    threshold_platelets = 150 # 閾値\n",
    "    df['thrombocytopenia'] = np.where(df['Platelets'] < threshold_platelets, 1, 0)\n",
    "\n",
    "    # アルカリ性リン酸塩ホスファターゼの上昇指標：\n",
    "    threshold_alk_phos_upper = 147\n",
    "    threshold_alk_phos_lower = 44\n",
    "    df['elevated_alk_phos'] = np.where((df['Alk_Phos'] > threshold_alk_phos_upper) | (df['Alk_Phos'] < threshold_alk_phos_lower), 1, 0)\n",
    "\n",
    "    # 正常な銅レベル\n",
    "    normal_copper_range = (62, 140)\n",
    "    df['normal_copper'] = np.where((df['Copper'] >= normal_copper_range[0]) & (df['Copper'] <= normal_copper_range[1]), 1, 0)\n",
    "\n",
    "    # アルブミンの正常範囲\n",
    "    normal_albumin_range = (3.4, 5.4)\n",
    "    df['normal_albumin'] = np.where((df['Albumin'] >= normal_albumin_range[1]), 1, 0)\n",
    "\n",
    "    # 正常なビリルビンレベル\n",
    "    normal_bilirubin_range = (0.2, 1.2)\n",
    "    df['normal_bilirubin'] = np.where((df['Bilirubin'] >= normal_bilirubin_range[0]) & (df['Bilirubin'] <= normal_bilirubin_range[1]), 1, 0)\n",
    "\n",
    "    # 診断日\n",
    "    df['DiagnosisDays'] = df['Age'] - df['N_Days']\n",
    "\n",
    "    # ビリルビン * アルブミン\n",
    "    df['Bilirubin_Albumin'] = df['Bilirubin'] * df['Albumin']\n",
    "\n",
    "    # 症状のスコア\n",
    "    symptom_columns = ['Ascites', 'Hepatomegaly', 'Spiders']\n",
    "    df['Symptom_Score'] = df[symptom_columns].sum(axis=1)\n",
    "\n",
    "    # 肝臓機能\n",
    "    liver_columns = ['Bilirubin', 'Albumin', 'Alk_Phos', 'SGOT']\n",
    "    df['Liver_Function_Index'] = df[liver_columns].mean(axis=1)\n",
    "\n",
    "    # リスクスコア\n",
    "    df['Risk_Score'] = df['Bilirubin'] + df['Albumin'] - df['Alk_Phos']\n",
    "\n",
    "    # 時間特徴量\n",
    "    df['Diag_Year'] = (df['N_Days'] / 365).astype(int)\n",
    "    df['Diag_Month'] = ((df['N_Days'] % 365) / 30).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "# 年齢に関する特徴量の追加\n",
    "def convert_days_to_years(age_in_days):\n",
    "    days_in_year = 365.25\n",
    "    age_in_years = age_in_days / days_in_year\n",
    "\n",
    "    return age_in_years\n",
    "\n",
    "def add_cols(df):\n",
    "    age = list(df.Age)\n",
    "    age_in_year = []\n",
    "    for i in age:\n",
    "        age_in_year.append(int(convert_days_to_years(i)))\n",
    "    df['Age_in_year'] = pd.Series(age_in_year)\n",
    "\n",
    "    return df\n",
    "\n",
    "# カテゴリ変数のエンコーディング\n",
    "# One-Hot Encoding\n",
    "def one_hot_encoding(df, cat_cols):\n",
    "    df = pd.get_dummies(df, columns=cat_cols)\n",
    "    # 目的変数を数値化(int64)する\n",
    "    df['Status'] = df['Status'].map({\"D\": 0, \"CL\": 1, \"C\": 2})\n",
    "    # 一緒にラベルエンコーディングすると、1,2,3になってしまいモデル学習できないため分割する\n",
    "\n",
    "    return df\n",
    "\n",
    "# LabelEncoding\n",
    "def label_encoder(df):\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        df[column] = df[column].fillna('').astype('str') # 欠損値の補完をする\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "    return df\n",
    "\n",
    "# 特徴量の選択\n",
    "# 特徴量の重要度評価\n",
    "def feature_importance_evaluation(df):\n",
    "    # データを対数変換する\n",
    "\n",
    "    # 訓練データをX(説明変数)とy（目的変数）に分割する\n",
    "    X = df.select_dtypes(include=['float', 'int'])\n",
    "    X = X.drop(['Status'], axis=1) # 目的変数を指定する\n",
    "    y = target # 目的変数を指定する\n",
    "\n",
    "    for column in X.columns.tolist():\n",
    "        X[column] = X[column].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "    # 特徴量の重要度評価\n",
    "    lgb = LGBMClassifier(\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    lgb.fit(X, y)\n",
    "    importance = lgb.feature_importances_\n",
    "\n",
    "    feature_importance = pd.DataFrame(data=importance, index=X.columns, columns=['importance']) \\\n",
    "        .sort_values(ascending=True, by='importance')\n",
    "\n",
    "    return feature_importance\n",
    "\n",
    "# 特徴量の削除\n",
    "def drop_columns(df):\n",
    "    drop_list = [\n",
    "        'index'\n",
    "    ]\n",
    "    dropped_df = df.drop(columns=drop_list)\n",
    "\n",
    "    return dropped_df\n",
    "\n",
    "# データセットの更新\n",
    "# 前処理\n",
    "df = add_cols(df)\n",
    "df = missing_values(df)\n",
    "df = outlier(df)\n",
    "# df = scaling(df) # 標準化したい時のみ実行する\n",
    "\n",
    "# 特徴量エンジニアリング\n",
    "df = create_new_features(df)\n",
    "df = drop_columns(df)\n",
    "\n",
    "cat_cols = ['Edema', 'Stage'] # One-Hot Encodingしたい水準数の少ないカラムを指定する\n",
    "df = one_hot_encoding(df, cat_cols)\n",
    "df = label_encoder(df)\n",
    "\n",
    "train = df[df.loc[:, 'id'] < 7905]\n",
    "test = df[df.loc[:, 'id'] >= 7905]\n",
    "\n",
    "train_x = train.drop(columns=['Status', 'id'])\n",
    "train_y = target\n",
    "test_x = test.drop(columns=['Status', 'id'])\n",
    "\n",
    "X = train_x.values\n",
    "y = train_y.values\n",
    "# y = y.astype(int)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# ID削除\n",
    "df.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "df.to_csv(OUTPUT_DIR + 'data.csv', index=False)\n",
    "\n",
    "# 確認 (data_import.py)\n",
    "def file_to_xy(filename):\n",
    "    data = pd.read_csv(filename, index_col=0)\n",
    "    print(f'読み込み完了 {filename}')\n",
    "    train = data[:7905].reset_index(drop=True)\n",
    "    test = data[7905:].reset_index(drop=True).drop('Status', axis=1)\n",
    "    # 目的変数と説明変数に分割\n",
    "    X = train.drop('Status', axis=1)\n",
    "    y = train['Status'].values\n",
    "    return data,test,train,X,y\n",
    "\n",
    "filename = OUTPUT_DIR + 'data.csv'\n",
    "data,test,train,X,y = file_to_xy(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815123f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:19.852462Z",
     "iopub.status.busy": "2023-12-21T13:54:19.851982Z",
     "iopub.status.idle": "2023-12-21T13:54:19.862392Z",
     "shell.execute_reply": "2023-12-21T13:54:19.861128Z"
    },
    "papermill": {
     "duration": 0.020252,
     "end_time": "2023-12-21T13:54:19.865131",
     "exception": false,
     "start_time": "2023-12-21T13:54:19.844879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a26469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:19.878649Z",
     "iopub.status.busy": "2023-12-21T13:54:19.878162Z",
     "iopub.status.idle": "2023-12-21T13:54:19.892047Z",
     "shell.execute_reply": "2023-12-21T13:54:19.890719Z"
    },
    "papermill": {
     "duration": 0.024436,
     "end_time": "2023-12-21T13:54:19.895295",
     "exception": false,
     "start_time": "2023-12-21T13:54:19.870859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_columns = df.select_dtypes(exclude=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d98e92b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:19.909643Z",
     "iopub.status.busy": "2023-12-21T13:54:19.908510Z",
     "iopub.status.idle": "2023-12-21T13:54:37.781922Z",
     "shell.execute_reply": "2023-12-21T13:54:37.780361Z"
    },
    "papermill": {
     "duration": 17.883503,
     "end_time": "2023-12-21T13:54:37.784700",
     "exception": false,
     "start_time": "2023-12-21T13:54:19.901197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss - CatBoost: 0.4592786069304633\n",
      "Log Loss - Gradient_Boosting: 0.4417445827289941\n",
      "Log Loss - LightGBM: 0.49196989587726075\n",
      "Log Loss - Ensemble: 0.4402829831313499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "cat_feature_indices = [df.columns.get_loc(col) for col in categorical_columns]\n",
    "cat_columns= categorical_columns[:-1]\n",
    "models = [\n",
    "    ('CatBoost', CatBoostClassifier(iterations=300, random_seed=42, logging_level='Silent', cat_features=cat_columns)),\n",
    "    ('Gradient_Boosting', GradientBoostingClassifier(n_estimators=150, random_state=42)),\n",
    "    ('LightGBM',   LGBMClassifier(n_estimators=150, random_state=42, categorical_feature=cat_feature_indices))\n",
    "]\n",
    "\n",
    "sum_prediction=0\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict_proba(X_test)\n",
    "    sum_prediction= predictions + sum_prediction\n",
    "    loss = log_loss(y_test, predictions)\n",
    "    print(f'Log Loss - {model_name}: {loss}')\n",
    "    \n",
    "Ensemble_pred= sum_prediction/5\n",
    "Ensemble_logloss= log_loss(y_test, Ensemble_pred)\n",
    "print(f'Log Loss - Ensemble: {Ensemble_logloss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b16e334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:37.799176Z",
     "iopub.status.busy": "2023-12-21T13:54:37.798372Z",
     "iopub.status.idle": "2023-12-21T13:54:37.805370Z",
     "shell.execute_reply": "2023-12-21T13:54:37.804399Z"
    },
    "papermill": {
     "duration": 0.016968,
     "end_time": "2023-12-21T13:54:37.807822",
     "exception": false,
     "start_time": "2023-12-21T13:54:37.790854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df= test.copy()\n",
    "# test_df['Age'] = test_df['Age'] // 365.25\n",
    "# test_df['N_Days'] = test_df['N_Days'] // 365.25\n",
    "# test_df.rename(columns={'N_Days': 'N_years'}, inplace=True)\n",
    "for colum in cat_columns:\n",
    "    test_df[colum]=le.fit_transform(test_df[colum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19234a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:37.822194Z",
     "iopub.status.busy": "2023-12-21T13:54:37.820965Z",
     "iopub.status.idle": "2023-12-21T13:54:59.378466Z",
     "shell.execute_reply": "2023-12-21T13:54:59.377335Z"
    },
    "papermill": {
     "duration": 21.567871,
     "end_time": "2023-12-21T13:54:59.381611",
     "exception": false,
     "start_time": "2023-12-21T13:54:37.813740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X.copy()\n",
    "y_train = y.copy()\n",
    "X_test = test_df  \n",
    "\n",
    "sum_predictions=0\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict_proba(X_test)\n",
    "    sum_predictions=sum_predictions+predictions\n",
    "\n",
    "ensemble_predictions = sum_predictions/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e44ef15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:59.396167Z",
     "iopub.status.busy": "2023-12-21T13:54:59.395287Z",
     "iopub.status.idle": "2023-12-21T13:54:59.404836Z",
     "shell.execute_reply": "2023-12-21T13:54:59.403634Z"
    },
    "papermill": {
     "duration": 0.01955,
     "end_time": "2023-12-21T13:54:59.407289",
     "exception": false,
     "start_time": "2023-12-21T13:54:59.387739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39756985, 0.01914351, 0.58328664],\n",
       "       [0.18717854, 0.14815842, 0.66466304],\n",
       "       [0.96105437, 0.01347337, 0.02547226],\n",
       "       ...,\n",
       "       [0.04392351, 0.00387841, 0.95219809],\n",
       "       [0.00695053, 0.00391933, 0.98913014],\n",
       "       [0.6902713 , 0.01205439, 0.29767431]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1240639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:59.421722Z",
     "iopub.status.busy": "2023-12-21T13:54:59.420854Z",
     "iopub.status.idle": "2023-12-21T13:54:59.443654Z",
     "shell.execute_reply": "2023-12-21T13:54:59.442435Z"
    },
    "papermill": {
     "duration": 0.032976,
     "end_time": "2023-12-21T13:54:59.446254",
     "exception": false,
     "start_time": "2023-12-21T13:54:59.413278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Status_D</th>\n",
       "      <th>Status_CL</th>\n",
       "      <th>Status_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7905</td>\n",
       "      <td>0.397570</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>0.583287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7906</td>\n",
       "      <td>0.187179</td>\n",
       "      <td>0.148158</td>\n",
       "      <td>0.664663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7907</td>\n",
       "      <td>0.961054</td>\n",
       "      <td>0.013473</td>\n",
       "      <td>0.025472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7908</td>\n",
       "      <td>0.044338</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.953399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7909</td>\n",
       "      <td>0.107533</td>\n",
       "      <td>0.019644</td>\n",
       "      <td>0.872823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>13171</td>\n",
       "      <td>0.034039</td>\n",
       "      <td>0.032474</td>\n",
       "      <td>0.933486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>13172</td>\n",
       "      <td>0.019761</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.978341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>13173</td>\n",
       "      <td>0.043924</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.952198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>13174</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.989130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>13175</td>\n",
       "      <td>0.690271</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.297674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5271 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  Status_D  Status_CL  Status_C\n",
       "0      7905  0.397570   0.019144  0.583287\n",
       "1      7906  0.187179   0.148158  0.664663\n",
       "2      7907  0.961054   0.013473  0.025472\n",
       "3      7908  0.044338   0.002263  0.953399\n",
       "4      7909  0.107533   0.019644  0.872823\n",
       "...     ...       ...        ...       ...\n",
       "5266  13171  0.034039   0.032474  0.933486\n",
       "5267  13172  0.019761   0.001898  0.978341\n",
       "5268  13173  0.043924   0.003878  0.952198\n",
       "5269  13174  0.006951   0.003919  0.989130\n",
       "5270  13175  0.690271   0.012054  0.297674\n",
       "\n",
       "[5271 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     df['Status'] = df['Status'].map({\"D\": 0, \"CL\": 1, \"C\": 2})\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': test_id,\n",
    "    'Status_D': ensemble_predictions[:, 0],\n",
    "    'Status_CL': ensemble_predictions[:, 1],\n",
    "    'Status_C': ensemble_predictions[:, 2]\n",
    "\n",
    "})\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442281c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T13:54:59.461770Z",
     "iopub.status.busy": "2023-12-21T13:54:59.460877Z",
     "iopub.status.idle": "2023-12-21T13:54:59.514085Z",
     "shell.execute_reply": "2023-12-21T13:54:59.512968Z"
    },
    "papermill": {
     "duration": 0.064392,
     "end_time": "2023-12-21T13:54:59.516982",
     "exception": false,
     "start_time": "2023-12-21T13:54:59.452590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7e168",
   "metadata": {
    "papermill": {
     "duration": 0.006022,
     "end_time": "2023-12-21T13:54:59.529892",
     "exception": false,
     "start_time": "2023-12-21T13:54:59.523870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7000181,
     "sourceId": 60893,
     "sourceType": "competition"
    },
    {
     "datasetId": 3873965,
     "sourceId": 6724823,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 50.331654,
   "end_time": "2023-12-21T13:55:00.458814",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-21T13:54:10.127160",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
