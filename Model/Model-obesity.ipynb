{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":68479,"databundleVersionId":7609535,"sourceType":"competition"},{"sourceId":7527406,"sourceType":"datasetVersion","datasetId":4383550}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":96.367425,"end_time":"2024-01-31T02:21:08.001702","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-31T02:19:31.634277","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1.246399,"end_time":"2024-01-31T02:19:37.471414","exception":false,"start_time":"2024-01-31T02:19:36.225015","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-01T06:33:15.484677Z","iopub.execute_input":"2024-02-01T06:33:15.485532Z","iopub.status.idle":"2024-02-01T06:33:15.498401Z","shell.execute_reply.started":"2024-02-01T06:33:15.485497Z","shell.execute_reply":"2024-02-01T06:33:15.497475Z"},"trusted":true},"execution_count":241,"outputs":[{"name":"stdout","text":"/kaggle/input/my-multi-class-prediction-of-obesity-risk/data.csv\n/kaggle/input/playground-series-s4e2/sample_submission.csv\n/kaggle/input/playground-series-s4e2/train.csv\n/kaggle/input/playground-series-s4e2/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **肥満リスクの多クラス予測**\n(Multi-Class Prediction of Obesity Risk)","metadata":{"papermill":{"duration":0.010789,"end_time":"2024-01-31T02:19:37.493551","exception":false,"start_time":"2024-01-31T02:19:37.482762","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 参考資料\n**書籍**\n\n\n**Kaggle**\n- The fat CatBoost😼\n\n**自分で作成したファイル**\n- 銀行解約データセットを使用した二項分類\n- 肝硬変の転帰の多クラス予測\n\n**その他**\n","metadata":{"papermill":{"duration":0.010721,"end_time":"2024-01-31T02:19:37.515181","exception":false,"start_time":"2024-01-31T02:19:37.504460","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nFILE_PATH = '/kaggle/input/playground-series-s4e2/'\nCREATE_DATA = '/kaggle/input/my-multi-class-prediction-of-obesity-risk'\n\n\n# 確認 (data_import.py)\ndef file_to_xy(filename):\n    data = pd.read_csv(filename, index_col=0)\n    print(f'読み込み完了 {filename}')\n    \n    target_col = 'NObeyesdad'\n    \n    train = data[:20758].reset_index(drop=True)\n    test = data[20758:].reset_index(drop=True).drop(target_col, axis=1) # 目的変数を指定する\n    # 目的変数と説明変数に分割\n    X = train.drop([target_col], axis=1) # 目的変数を指定する\n    y = train[target_col].values # 目的変数を指定する\n\n    return data,test,train,X,y\n\nfilename = 'data.csv'\ndata,test,train,X,y = file_to_xy(CREATE_DATA + '/' + filename)","metadata":{"papermill":{"duration":1.632186,"end_time":"2024-01-31T02:19:39.158293","exception":false,"start_time":"2024-01-31T02:19:37.526107","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-01T06:33:15.499912Z","iopub.execute_input":"2024-02-01T06:33:15.500243Z","iopub.status.idle":"2024-02-01T06:33:15.569217Z","shell.execute_reply.started":"2024-02-01T06:33:15.500211Z","shell.execute_reply":"2024-02-01T06:33:15.568268Z"},"trusted":true},"execution_count":242,"outputs":[{"name":"stdout","text":"読み込み完了 /kaggle/input/my-multi-class-prediction-of-obesity-risk/data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"X = X.copy()\ny = y.copy()","metadata":{"papermill":{"duration":0.028882,"end_time":"2024-01-31T02:19:39.198609","exception":false,"start_time":"2024-01-31T02:19:39.169727","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-01T06:33:15.570276Z","iopub.execute_input":"2024-02-01T06:33:15.570962Z","iopub.status.idle":"2024-02-01T06:33:15.575522Z","shell.execute_reply.started":"2024-02-01T06:33:15.570933Z","shell.execute_reply":"2024-02-01T06:33:15.574491Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"markdown","source":"# 機械学習モデルの構築・学習・予測","metadata":{"papermill":{"duration":0.011093,"end_time":"2024-01-31T02:19:39.220901","exception":false,"start_time":"2024-01-31T02:19:39.209808","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## ライブラリのインポート","metadata":{"papermill":{"duration":0.011036,"end_time":"2024-01-31T02:19:39.242907","exception":false,"start_time":"2024-01-31T02:19:39.231871","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# 評価指標\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, mean_absolute_error, mean_squared_error, r2_score\n\n# 機械学習モデル\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n\n# 実験\nimport datetime\nimport pickle\n\n\nsample_sub = pd.read_csv(FILE_PATH + \"sample_submission.csv\")","metadata":{"papermill":{"duration":8.051194,"end_time":"2024-01-31T02:19:47.305082","exception":false,"start_time":"2024-01-31T02:19:39.253888","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-01T06:33:15.577200Z","iopub.execute_input":"2024-02-01T06:33:15.577496Z","iopub.status.idle":"2024-02-01T06:33:15.594445Z","shell.execute_reply.started":"2024-02-01T06:33:15.577472Z","shell.execute_reply":"2024-02-01T06:33:15.593692Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"markdown","source":"## データの分割","metadata":{"papermill":{"duration":0.01183,"end_time":"2024-01-31T02:19:47.330325","exception":false,"start_time":"2024-01-31T02:19:47.318495","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"papermill":{"duration":0.055942,"end_time":"2024-01-31T02:19:47.398269","exception":false,"start_time":"2024-01-31T02:19:47.342327","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-01T06:33:15.634062Z","iopub.execute_input":"2024-02-01T06:33:15.634310Z","iopub.status.idle":"2024-02-01T06:33:15.643477Z","shell.execute_reply.started":"2024-02-01T06:33:15.634288Z","shell.execute_reply":"2024-02-01T06:33:15.642514Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"markdown","source":"## ハイパーパラメータ","metadata":{}},{"cell_type":"code","source":"xgb_params = {'max_depth': 10,\n    'min_child_weight': 1,\n    'learning_rate': 0.733656719765889,\n    'n_estimators': 696,\n    'subsample': 0.7928524918864644,\n    'colsample_bytree': 0.1345360036201174,\n    'random_state': 42,\n    'njobs': -1}\n\ncat_params = {'iterations': 526,\n    'depth': 3,\n    'min_data_in_leaf': 13,\n    'learning_rate': 0.0008029819794568197}","metadata":{"execution":{"iopub.status.busy":"2024-02-01T06:33:15.645452Z","iopub.execute_input":"2024-02-01T06:33:15.646600Z","iopub.status.idle":"2024-02-01T06:33:15.652312Z","shell.execute_reply.started":"2024-02-01T06:33:15.646574Z","shell.execute_reply":"2024-02-01T06:33:15.651583Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"markdown","source":"## モデルファイルと評価結果を出力する（ファイルの出力あり）, Main","metadata":{"papermill":{"duration":0.014865,"end_time":"2024-01-31T02:19:55.768064","exception":false,"start_time":"2024-01-31T02:19:55.753199","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def make_model_and_eval(model, X_train, X_test, y_train, y_test):\n    model.fit(X_train, y_train)\n    y_pred_train = model.predict(X_train)\n    y_pred_test = model.predict(X_test)\n    \n    # accuracy\n    acc_train = accuracy_score(y_train, y_pred_train)\n    acc_test = accuracy_score(y_test, y_pred_test)\n    # F1_score\n    f1_train = f1_score(y_train, y_pred_train, average='macro')\n    f1_test = f1_score(y_test, y_pred_test, average='macro')\n    # recall\n    recall_train = recall_score(y_train, y_pred_train, average='macro')\n    recall_test = recall_score(y_test, y_pred_test, average='macro')\n    # precision\n    precision_train = precision_score(y_train, y_pred_train, average='macro')\n    precision_test = precision_score(y_test, y_pred_test, average='macro')\n#    # AUC\n#     auc_train = roc_auc_score(y_train, y_pred_train)\n#     auc_test = roc_auc_score(y_test, y_pred_test)\n   # MAE\n    mae_train = mean_absolute_error(y_train, y_pred_train)\n    mae_test = mean_absolute_error(y_test, y_pred_test)\n   # MSE\n    mse_train = mean_squared_error(y_train, y_pred_train)\n    mse_test = mean_squared_error(y_test, y_pred_test)\n   # RMSE\n    rmse_train = np.sqrt(mse_train)\n    rmse_test = np.sqrt(mse_test)\n   # r2_score\n    r2_train = r2_score(y_train, y_pred_train)\n    r2_test = r2_score(y_test, y_pred_test)\n\n#     tn_train, fp_train, fn_train, tp_train = confusion_matrix(y_train, y_pred_train).ravel()\n#     tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_pred_test).ravel()\n    score_train = pd.DataFrame({'DataCategory':['Train'],\n#                                'auc':[auc_train],\n                               'accuracy':[acc_train],\n                               'f1':[f1_train],\n                               'recall':[recall_train],\n                               'precision':[precision_train],\n                               'MAE':[mae_train],\n                               'MSE':[mse_train],\n                               'RMSE':[rmse_train],\n                               'r2':[r2_train],\n#                                'tp':[tp_train],\n#                                'fn':[fn_train],\n#                                'fp':[fp_train],\n#                                'tn':[tn_train]\n                               })\n    score_test = pd.DataFrame({'DataCategory':['Valid'],\n#                               'auc':[auc_test],\n                              'accuracy':[acc_test],\n                              'f1':[f1_test],\n                              'recall':[recall_test],\n                              'precision':[precision_test],\n                              'MAE':[mae_test],\n                              'MSE':[mse_test],\n                              'RMSE':[rmse_train],\n                              'r2':[r2_train],\n#                               'tp':[tp_test],\n#                               'fn':[fn_test],\n#                               'fp':[fp_test],\n#                               'tn':[tn_test]\n                              })\n    score = pd.concat([score_train, score_test], ignore_index=True)\n    \n    importance = pd.DataFrame({'cols': X_train.columns,\n                              'importance': model.feature_importances_})\n    importance = importance.sort_values('importance', ascending=False)\n    cols = pd.DataFrame({'X_cols': X_train.columns})\n    display(score)\n    \n    return score, importance, model, cols","metadata":{"papermill":{"duration":0.031862,"end_time":"2024-01-31T02:19:55.814837","exception":false,"start_time":"2024-01-31T02:19:55.782975","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-01T06:33:15.653775Z","iopub.execute_input":"2024-02-01T06:33:15.654238Z","iopub.status.idle":"2024-02-01T06:33:15.667822Z","shell.execute_reply.started":"2024-02-01T06:33:15.654207Z","shell.execute_reply":"2024-02-01T06:33:15.667018Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"now = datetime.datetime.now().strftime(\"%Y%m%d%H\")\ntarget_output_dir = 'results_' + now\n\nos.makedirs(target_output_dir, exist_ok=True)\nprint(target_output_dir)\n\n\n\nmodels = {'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42), \n          'RandomForest':RandomForestClassifier(random_state=42),\n          'GradientBoostingClassifier':GradientBoostingClassifier(random_state=42),\n          'lightgbm': LGBMClassifier(random_state=42),\n          'xgboost': XGBClassifier(random_state=42),\n#           'BaggingClassifier': BaggingClassifier(random_state=42),\n          'AdaBoostClassifier': AdaBoostClassifier(random_state=42),\n#           'CatBoostClassifier': CatBoostClassifier(**cat_params),\n         }\n\nscore_all = []\nimportance_all = []\nfor model_name, model in models.items():\n    print(model_name)\n    score, importance, model, cols = make_model_and_eval(model, X_train, X_valid, y_train, y_valid)\n    score['model_name'] = model_name\n    importance['model_name'] = model_name\n    \n    model_names = f'model_{model_name}.pickle'\n    model_path = os.path.join(target_output_dir, model_names)\n    with open(model_path, mode='wb') as f:\n        pickle.dump(model, f, protocol=2)\n    score_all.append(score)\n    importance_all.append(importance)\nscore_all = pd.concat(score_all, ignore_index=True)\nimportance_all = pd.concat(importance_all, ignore_index=True)\ncols = pd.DataFrame({'X_cols':X_train.columns})\n\nscore_name = 'score.csv'\nimportance_name = 'importance.csv'\ncols_name = 'X_cols.csv'\n\nscore_path = os.path.join(target_output_dir, score_name)\nimportance_path = os.path.join(target_output_dir, importance_name)\ncols_path = os.path.join(target_output_dir, cols_name)\n\nscore_all.to_csv(score_path, index=False)\nimportance_all.to_csv(importance_path, index=False)\ncols.to_csv(cols_path, index=False)","metadata":{"papermill":{"duration":68.500443,"end_time":"2024-01-31T02:21:04.330307","exception":false,"start_time":"2024-01-31T02:19:55.829864","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-01T06:33:15.669689Z","iopub.execute_input":"2024-02-01T06:33:15.669951Z","iopub.status.idle":"2024-02-01T06:33:41.595325Z","shell.execute_reply.started":"2024-02-01T06:33:15.669928Z","shell.execute_reply":"2024-02-01T06:33:41.594587Z"},"trusted":true},"execution_count":248,"outputs":[{"name":"stdout","text":"results_2024020106\nDecisionTreeClassifier\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  DataCategory  accuracy        f1    recall  precision       MAE       MSE  \\\n0        Train  1.000000  1.000000  1.000000   1.000000  0.000000  0.000000   \n1        Valid  0.847303  0.831943  0.831859   0.832185  0.376204  1.277457   \n\n   RMSE   r2  \n0   0.0  1.0  \n1   0.0  1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataCategory</th>\n      <th>accuracy</th>\n      <th>f1</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Train</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Valid</td>\n      <td>0.847303</td>\n      <td>0.831943</td>\n      <td>0.831859</td>\n      <td>0.832185</td>\n      <td>0.376204</td>\n      <td>1.277457</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"RandomForest\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  DataCategory  accuracy        f1    recall  precision       MAE       MSE  \\\n0        Train  1.000000  1.000000  1.000000   1.000000  0.000000  0.000000   \n1        Valid  0.893064  0.881411  0.880445   0.882909  0.271195  0.942678   \n\n   RMSE   r2  \n0   0.0  1.0  \n1   0.0  1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataCategory</th>\n      <th>accuracy</th>\n      <th>f1</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Train</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Valid</td>\n      <td>0.893064</td>\n      <td>0.881411</td>\n      <td>0.880445</td>\n      <td>0.882909</td>\n      <td>0.271195</td>\n      <td>0.942678</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"GradientBoostingClassifier\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  DataCategory  accuracy        f1    recall  precision       MAE       MSE  \\\n0        Train  0.920330  0.911652  0.911558   0.911907  0.197037  0.671805   \n1        Valid  0.900771  0.890185  0.889953   0.890471  0.244220  0.831888   \n\n       RMSE        r2  \n0  0.819637  0.811767  \n1  0.819637  0.811767  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataCategory</th>\n      <th>accuracy</th>\n      <th>f1</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Train</td>\n      <td>0.920330</td>\n      <td>0.911652</td>\n      <td>0.911558</td>\n      <td>0.911907</td>\n      <td>0.197037</td>\n      <td>0.671805</td>\n      <td>0.819637</td>\n      <td>0.811767</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Valid</td>\n      <td>0.900771</td>\n      <td>0.890185</td>\n      <td>0.889953</td>\n      <td>0.890471</td>\n      <td>0.244220</td>\n      <td>0.831888</td>\n      <td>0.819637</td>\n      <td>0.811767</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"lightgbm\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001830 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2043\n[LightGBM] [Info] Number of data points in the train set: 16606, number of used features: 16\n[LightGBM] [Info] Start training from score -2.117117\n[LightGBM] [Info] Start training from score -1.911230\n[LightGBM] [Info] Start training from score -1.948141\n[LightGBM] [Info] Start training from score -1.857720\n[LightGBM] [Info] Start training from score -1.633574\n[LightGBM] [Info] Start training from score -2.145531\n[LightGBM] [Info] Start training from score -2.112625\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  DataCategory  accuracy        f1    recall  precision       MAE       MSE  \\\n0        Train  0.979766  0.977217  0.977060   0.977446  0.051728  0.177827   \n1        Valid  0.903420  0.893093  0.892806   0.893439  0.239403  0.811175   \n\n       RMSE        r2  \n0  0.421696  0.950175  \n1  0.421696  0.950175  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataCategory</th>\n      <th>accuracy</th>\n      <th>f1</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Train</td>\n      <td>0.979766</td>\n      <td>0.977217</td>\n      <td>0.977060</td>\n      <td>0.977446</td>\n      <td>0.051728</td>\n      <td>0.177827</td>\n      <td>0.421696</td>\n      <td>0.950175</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Valid</td>\n      <td>0.903420</td>\n      <td>0.893093</td>\n      <td>0.892806</td>\n      <td>0.893439</td>\n      <td>0.239403</td>\n      <td>0.811175</td>\n      <td>0.421696</td>\n      <td>0.950175</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"xgboost\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  DataCategory  accuracy        f1    recall  precision       MAE       MSE  \\\n0        Train  0.985848  0.984105  0.984044   0.984209  0.035529  0.121884   \n1        Valid  0.904624  0.894678  0.894613   0.894786  0.240848  0.835260   \n\n       RMSE       r2  \n0  0.349118  0.96585  \n1  0.349118  0.96585  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataCategory</th>\n      <th>accuracy</th>\n      <th>f1</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Train</td>\n      <td>0.985848</td>\n      <td>0.984105</td>\n      <td>0.984044</td>\n      <td>0.984209</td>\n      <td>0.035529</td>\n      <td>0.121884</td>\n      <td>0.349118</td>\n      <td>0.96585</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Valid</td>\n      <td>0.904624</td>\n      <td>0.894678</td>\n      <td>0.894613</td>\n      <td>0.894786</td>\n      <td>0.240848</td>\n      <td>0.835260</td>\n      <td>0.349118</td>\n      <td>0.96585</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"AdaBoostClassifier\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  DataCategory  accuracy        f1    recall  precision       MAE       MSE  \\\n0        Train  0.629411  0.567442  0.599230   0.621253  0.884500  2.879682   \n1        Valid  0.625482  0.558456  0.590388   0.609543  0.905588  2.980250   \n\n       RMSE        r2  \n0  1.696963  0.193144  \n1  1.696963  0.193144  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DataCategory</th>\n      <th>accuracy</th>\n      <th>f1</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Train</td>\n      <td>0.629411</td>\n      <td>0.567442</td>\n      <td>0.599230</td>\n      <td>0.621253</td>\n      <td>0.884500</td>\n      <td>2.879682</td>\n      <td>1.696963</td>\n      <td>0.193144</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Valid</td>\n      <td>0.625482</td>\n      <td>0.558456</td>\n      <td>0.590388</td>\n      <td>0.609543</td>\n      <td>0.905588</td>\n      <td>2.980250</td>\n      <td>1.696963</td>\n      <td>0.193144</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### pickleファイルのインポート","metadata":{"papermill":{"duration":0.0163,"end_time":"2024-01-31T02:21:04.363965","exception":false,"start_time":"2024-01-31T02:21:04.347665","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pickle\n\nmodel_name = 'model_xgboost.pickle'\n\nmodel_path = os.path.join(target_output_dir, model_name)\n\nwith open(model_path, mode='rb') as f:\n    model = pickle.load(f)\n    \nprint(model)","metadata":{"papermill":{"duration":0.031522,"end_time":"2024-01-31T02:21:04.411796","exception":false,"start_time":"2024-01-31T02:21:04.380274","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-01T06:33:41.596312Z","iopub.execute_input":"2024-02-01T06:33:41.596630Z","iopub.status.idle":"2024-02-01T06:33:41.622938Z","shell.execute_reply.started":"2024-02-01T06:33:41.596605Z","shell.execute_reply":"2024-02-01T06:33:41.622052Z"},"trusted":true},"execution_count":249,"outputs":[{"name":"stdout","text":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softprob', ...)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## モデルの予測","metadata":{"papermill":{"duration":0.016257,"end_time":"2024-01-31T02:21:04.444585","exception":false,"start_time":"2024-01-31T02:21:04.428328","status":"completed"},"tags":[]}},{"cell_type":"code","source":"target_col = 'NObeyesdad'\nsample_sub[target_col] = model.predict(test)","metadata":{"papermill":{"duration":0.681385,"end_time":"2024-01-31T02:21:05.142508","exception":false,"start_time":"2024-01-31T02:21:04.461123","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-01T06:33:41.625228Z","iopub.execute_input":"2024-02-01T06:33:41.625520Z","iopub.status.idle":"2024-02-01T06:33:41.716518Z","shell.execute_reply.started":"2024-02-01T06:33:41.625495Z","shell.execute_reply":"2024-02-01T06:33:41.715789Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"markdown","source":"# 提出","metadata":{"papermill":{"duration":0.016531,"end_time":"2024-01-31T02:21:05.177878","exception":false,"start_time":"2024-01-31T02:21:05.161347","status":"completed"},"tags":[]}},{"cell_type":"code","source":"inverse_mapping = {\n                   0: 'Insufficient_Weight',\n                   1: 'Normal_Weight', \n                   2: 'Obesity_Type_I',\n                   3: 'Obesity_Type_II', \n                   4: 'Obesity_Type_III', \n                   5: 'Overweight_Level_I', \n                   6: 'Overweight_Level_II'\n                  }\n\nsample_sub[target_col] = sample_sub[target_col].map(inverse_mapping)\nsample_sub.to_csv('submission.csv', index=False)\nsample_sub.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T06:33:41.720491Z","iopub.execute_input":"2024-02-01T06:33:41.722483Z","iopub.status.idle":"2024-02-01T06:33:41.760454Z","shell.execute_reply.started":"2024-02-01T06:33:41.722456Z","shell.execute_reply":"2024-02-01T06:33:41.759591Z"},"trusted":true},"execution_count":251,"outputs":[{"execution_count":251,"output_type":"execute_result","data":{"text/plain":"      id          NObeyesdad\n0  20758     Obesity_Type_II\n1  20759  Overweight_Level_I\n2  20760    Obesity_Type_III\n3  20761      Obesity_Type_I\n4  20762    Obesity_Type_III","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>NObeyesdad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20758</td>\n      <td>Obesity_Type_II</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20759</td>\n      <td>Overweight_Level_I</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20760</td>\n      <td>Obesity_Type_III</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20761</td>\n      <td>Obesity_Type_I</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20762</td>\n      <td>Obesity_Type_III</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 導入検討","metadata":{}},{"cell_type":"markdown","source":"### 標準化を行なったモデル","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\n\nclf1 = LogisticRegression(penalty='l2',\n                         C=0.001,\n                         solver='lbfgs',\n                         random_state=1)\nclf2 = DecisionTreeClassifier(max_depth=1,\n                             criterion='entropy',\n                             random_state=0)\nclf3 = KNeighborsClassifier(n_neighbors=1,\n                           p=2,\n                           metric='minkowski')\n\npipe1 = Pipeline([['sc', StandardScaler()],\n                 ['clf', clf1]])\npipe3 = Pipeline([['sc', StandardScaler()],\n                 ['clf', clf3]])\n\nclf_labels = ['Logistic regression', 'Decision tree', 'KNN']\n\nprint('10-fold cross validation:\\n')\n\nfor clf, label in zip([pipe1, clf2, pipe3], clf_labels):\n    scores = cross_val_score(estimator=clf,\n                            X=X_train,\n                            y=y_train,\n                            cv=10,\n                            scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))","metadata":{"execution":{"iopub.status.busy":"2024-02-01T06:33:41.761558Z","iopub.execute_input":"2024-02-01T06:33:41.761830Z","iopub.status.idle":"2024-02-01T06:33:44.804563Z","shell.execute_reply.started":"2024-02-01T06:33:41.761806Z","shell.execute_reply":"2024-02-01T06:33:44.803647Z"},"trusted":true},"execution_count":252,"outputs":[{"name":"stdout","text":"10-fold cross validation:\n\nAccuracy: 0.64 (+/- 0.01) [Logistic regression]\nAccuracy: 0.34 (+/- 0.00) [Decision tree]\nAccuracy: 0.73 (+/- 0.01) [KNN]\n","output_type":"stream"}]}]}