{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":60893,"databundleVersionId":7000181,"sourceType":"competition"},{"sourceId":7251079,"sourceType":"datasetVersion","datasetId":4201083},{"sourceId":7236737,"sourceType":"datasetVersion","datasetId":4190832}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-21T13:19:16.824559Z","iopub.execute_input":"2023-12-21T13:19:16.825285Z","iopub.status.idle":"2023-12-21T13:19:16.842565Z","shell.execute_reply.started":"2023-12-21T13:19:16.825239Z","shell.execute_reply":"2023-12-21T13:19:16.841465Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"/kaggle/input/datascience-github/LICENSE\n/kaggle/input/datascience-github/GithubwithKaggle/processor-e22-horses-1221.ipynb\n/kaggle/input/datascience-github/GithubwithKaggle/eda-e22-horses-1221.ipynb\n/kaggle/input/datascience-github/GithubwithKaggle/.gitkeep\n/kaggle/input/datascience-github/EDA/EDA_Horses.ipynb\n/kaggle/input/datascience-github/EDA/EDA_Smoker.ipynb\n/kaggle/input/datascience-github/EDA/EDA_titanic.ipynb\n/kaggle/input/datascience-github/EDA/EDA-2_Cirrhosis.ipynb\n/kaggle/input/datascience-github/EDA/EDA_Credit.ipynb\n/kaggle/input/datascience-github/EDA/EDA-2_Mohs-Hardness.ipynb\n/kaggle/input/datascience-github/EDA/.gitkeep\n/kaggle/input/datascience-github/EDA/EDA_Software.ipynb\n/kaggle/input/datascience-github/Slide/Multi-Class Prediction of Cirrhosis Outcomes.pdf\n/kaggle/input/datascience-github/Slide/Binary Classification with a Software Defects Dataset.pdf\n/kaggle/input/datascience-github/Slide/Binary Prediction of Smoker Status using Bio-Signals.pdf\n/kaggle/input/datascience-github/Slide/Regression-with-a-Mohs-Hardness-Dataset.pdf\n/kaggle/input/datascience-github/Slide/.gitkeep\n/kaggle/input/datascience-github/Processor/processor_titanic.ipynb\n/kaggle/input/datascience-github/Processor/processor_3_Credit.py\n/kaggle/input/datascience-github/Processor/processor_2_Credit.ipynb\n/kaggle/input/datascience-github/Processor/processor_Horses.ipynb\n/kaggle/input/datascience-github/Processor/processor.py\n/kaggle/input/datascience-github/Processor/.gitkeep\n/kaggle/input/datascience-github/Processor/processor_2_Cirrhosis.ipynb\n/kaggle/input/datascience-github/Processor/processor_2.ipynb\n/kaggle/input/datascience-github/Processor/processor.ipynb\n/kaggle/input/datascience-github/archive/中古車の価格予測チャレンジ0724_2.ipynb\n/kaggle/input/datascience-github/archive/中古車の価格予測チャレンジ.ipynb\n/kaggle/input/datascience-github/archive/.gitkeep\n/kaggle/input/mydata/data.csv\n/kaggle/input/playground-series-s3e26/sample_submission.csv\n/kaggle/input/playground-series-s3e26/train.csv\n/kaggle/input/playground-series-s3e26/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 処理","metadata":{}},{"cell_type":"code","source":"# ライブラリ・データセットのインポート\nimport numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import LabelEncoder\n\n## 実行時間を調べるために使う\nimport datetime\nimport time\nimport math\n\nstart_time = time.time()\n\ndef changeHMS(s):\n    h = math.floor(s / 3600)\n    if h > 0:\n        s = s - h * 3600\n        indi_h = str(h) + 'h'\n    else:\n        indi_h = ''\n    m = math.floor(s / 60)\n    if m > 0:\n        indi_m = str(m) + 'm'\n    else:\n        indi_m = ''\n    s = math.floor(s % 60)\n    time = indi_h + indi_m + str(s) + 's'\n    return time\n\nFILE_PATH = '/kaggle/input/playground-series-s3e26/'\nOUTPUT_DIR = '/kaggle/working/'\n\ntrain = pd.read_csv(FILE_PATH + 'train.csv')\ntest = pd.read_csv(FILE_PATH + 'test.csv')\n\ntest_id = test['id']\n\ntarget = train['Status']\n\ntarget_name = str(train.iloc[:, [18]].columns.tolist()) # カラム数-2の値が目的変数\n\ndf = pd.concat([train, test], axis=0)\ndf.reset_index(inplace=True)\n\n# 説明変数をデータ型ごとに代入する\nnumerical_features = df._get_numeric_data().columns\ncategorical_features = df.drop(numerical_features, axis=1).columns\nnumerical_features = numerical_features.drop('id')\n\n# 前処理\n# 欠損値の補完\ndef missing_values(df):\n\n    return df\n\n# 外れ値の削除\ndef outlier(df):\n\n    return df\n\n# MinMaxScaler(正規化)\ndef scaling(df):\n    df_scale = df[numerical_features]\n    sc = MinMaxScaler()\n    df[numerical_features] = pd.DataFrame(sc.fit_transform(df_scale), columns = df_scale.columns)\n\n    return df\n\n# 特徴量エンジニアリング\n# 特徴量の作成\ndef create_new_features(df):\n    # 血小板減少症インジケーター\n    threshold_platelets = 150 # 閾値\n    df['thrombocytopenia'] = np.where(df['Platelets'] < threshold_platelets, 1, 0)\n\n    # アルカリ性リン酸塩ホスファターゼの上昇指標：\n    threshold_alk_phos_upper = 147\n    threshold_alk_phos_lower = 44\n    df['elevated_alk_phos'] = np.where((df['Alk_Phos'] > threshold_alk_phos_upper) | (df['Alk_Phos'] < threshold_alk_phos_lower), 1, 0)\n\n    # 正常な銅レベル\n    normal_copper_range = (62, 140)\n    df['normal_copper'] = np.where((df['Copper'] >= normal_copper_range[0]) & (df['Copper'] <= normal_copper_range[1]), 1, 0)\n\n    # アルブミンの正常範囲\n    normal_albumin_range = (3.4, 5.4)\n    df['normal_albumin'] = np.where((df['Albumin'] >= normal_albumin_range[1]), 1, 0)\n\n    # 正常なビリルビンレベル\n    normal_bilirubin_range = (0.2, 1.2)\n    df['normal_bilirubin'] = np.where((df['Bilirubin'] >= normal_bilirubin_range[0]) & (df['Bilirubin'] <= normal_bilirubin_range[1]), 1, 0)\n\n    # 診断日\n    df['DiagnosisDays'] = df['Age'] - df['N_Days']\n\n    # ビリルビン * アルブミン\n    df['Bilirubin_Albumin'] = df['Bilirubin'] * df['Albumin']\n\n    # 症状のスコア\n    symptom_columns = ['Ascites', 'Hepatomegaly', 'Spiders']\n    df['Symptom_Score'] = df[symptom_columns].sum(axis=1)\n\n    # 肝臓機能\n    liver_columns = ['Bilirubin', 'Albumin', 'Alk_Phos', 'SGOT']\n    df['Liver_Function_Index'] = df[liver_columns].mean(axis=1)\n\n    # リスクスコア\n    df['Risk_Score'] = df['Bilirubin'] + df['Albumin'] - df['Alk_Phos']\n\n    # 時間特徴量\n    df['Diag_Year'] = (df['N_Days'] / 365).astype(int)\n    df['Diag_Month'] = ((df['N_Days'] % 365) / 30).astype(int)\n\n    return df\n\n# 年齢に関する特徴量の追加\ndef convert_days_to_years(age_in_days):\n    days_in_year = 365.25\n    age_in_years = age_in_days / days_in_year\n\n    return age_in_years\n\ndef add_cols(df):\n    age = list(df.Age)\n    age_in_year = []\n    for i in age:\n        age_in_year.append(int(convert_days_to_years(i)))\n    df['Age_in_year'] = pd.Series(age_in_year)\n\n    return df\n\n# カテゴリ変数のエンコーディング\n# One-Hot Encoding\ndef one_hot_encoding(df, cat_cols):\n    df = pd.get_dummies(df, columns=cat_cols)\n    # 目的変数を数値化(int64)する\n    df['Status'] = df['Status'].map({\"D\": 0, \"CL\": 1, \"C\": 2})\n    # 一緒にラベルエンコーディングすると、1,2,3になってしまいモデル学習できないため分割する\n\n    return df\n\n# LabelEncoding\ndef label_encoder(df):\n    categorical_columns = df.select_dtypes(include=['object']).columns\n    for column in categorical_columns:\n        df[column] = df[column].fillna('').astype('str') # 欠損値の補完をする\n        label_encoder = LabelEncoder()\n        df[column] = label_encoder.fit_transform(df[column])\n\n    return df\n\n# 特徴量の選択\n# 特徴量の重要度評価\ndef feature_importance_evaluation(df):\n    # データを対数変換する\n\n    # 訓練データをX(説明変数)とy（目的変数）に分割する\n    X = df.select_dtypes(include=['float', 'int'])\n    X = X.drop(['Status'], axis=1) # 目的変数を指定する\n    y = target # 目的変数を指定する\n\n    for column in X.columns.tolist():\n        X[column] = X[column].apply(lambda x: np.log(x + 1))\n\n    # 特徴量の重要度評価\n    lgb = LGBMClassifier(\n        random_state=42,\n    )\n\n    lgb.fit(X, y)\n    importance = lgb.feature_importances_\n\n    feature_importance = pd.DataFrame(data=importance, index=X.columns, columns=['importance']) \\\n        .sort_values(ascending=True, by='importance')\n\n    return feature_importance\n\n# 特徴量の削除\ndef drop_columns(df):\n    drop_list = [\n        'index'\n    ]\n    dropped_df = df.drop(columns=drop_list)\n\n    return dropped_df\n\n# データセットの更新\n# 前処理\ndf = add_cols(df)\ndf = missing_values(df)\ndf = outlier(df)\n# df = scaling(df) # 標準化したい時のみ実行する\n\n# 特徴量エンジニアリング\ndf = create_new_features(df)\ndf = drop_columns(df)\n\ncat_cols = ['Edema', 'Stage'] # One-Hot Encodingしたい水準数の少ないカラムを指定する\ndf = one_hot_encoding(df, cat_cols)\ndf = label_encoder(df)\n\ntrain = df[df.loc[:, 'id'] < 7905]\ntest = df[df.loc[:, 'id'] >= 7905]\n\ntrain_x = train.drop(columns=['Status', 'id'])\ntrain_y = target\ntest_x = test.drop(columns=['Status', 'id'])\n\nX = train_x.values\ny = train_y.values\n# y = y.astype(int)\n\ndf.head()\n\n# ID削除\ndf.drop(\"id\", axis=1, inplace=True)\n\ndf.to_csv(OUTPUT_DIR + 'data.csv', index=False)\n\n# 確認 (data_import.py)\ndef file_to_xy(filename):\n    data = pd.read_csv(filename, index_col=0)\n    print(f'読み込み完了 {filename}')\n    train = data[:7905].reset_index(drop=True)\n    test = data[7905:].reset_index(drop=True).drop('Status', axis=1)\n    # 目的変数と説明変数に分割\n    X = train.drop('Status', axis=1)\n    y = train['Status'].values\n    return data,test,train,X,y\n\nfilename = OUTPUT_DIR + 'data.csv'\ndata,test,train,X,y = file_to_xy(filename)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T13:19:16.844580Z","iopub.execute_input":"2023-12-21T13:19:16.844970Z","iopub.status.idle":"2023-12-21T13:19:17.391220Z","shell.execute_reply.started":"2023-12-21T13:19:16.844921Z","shell.execute_reply":"2023-12-21T13:19:17.390119Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"読み込み完了 /kaggle/working/data.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# モデルの構築・学習","metadata":{}},{"cell_type":"markdown","source":"# 参考資料\n**書籍**\n\n\n**Kaggle**\n- [For Beginners by a Beginner](https://www.kaggle.com/code/juniorbertrand/for-beginners-by-a-beginner)\n\n\n**自分で作成したファイル**\n\n**その他**\n","metadata":{}},{"cell_type":"code","source":"train = train.copy()\ntrain_x = X.copy()\ntrain_y = y.copy()\ntest_x = test.copy()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T13:19:17.392479Z","iopub.execute_input":"2023-12-21T13:19:17.392903Z","iopub.status.idle":"2023-12-21T13:19:17.399903Z","shell.execute_reply.started":"2023-12-21T13:19:17.392872Z","shell.execute_reply":"2023-12-21T13:19:17.398568Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# import xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2023-12-21T13:19:17.401548Z","iopub.execute_input":"2023-12-21T13:19:17.401923Z","iopub.status.idle":"2023-12-21T13:19:17.409162Z","shell.execute_reply.started":"2023-12-21T13:19:17.401888Z","shell.execute_reply":"2023-12-21T13:19:17.408013Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost","metadata":{}},{"cell_type":"code","source":"# class Model:\n#     def __init__(self, params=None):\n#         self.model = None\n#         if params is None:\n#             self.params = {}\n#         else:\n#             self.params = params\n            \n#     # 学習\n#     def fit(self, tr_x, tr_y):\n#         params = {'objective': 'multi:softmax', 'num_class':3,\n#                   'random_state': 42\n#                  }\n#         params.update(self.params)\n#         num_round = 10\n#         dtrain = xgb.DMatrix(tr_x, label=tr_y)\n#         self.model = xgb.train(params, dtrain, num_round)\n        \n#     # 予測値を出力する\n#     def predict(self, x):\n#         data = xgb.DMatrix(x)\n#         pred = self.model.predict(data)\n        \n#         return pred","metadata":{"execution":{"iopub.status.busy":"2023-12-21T13:19:17.412876Z","iopub.execute_input":"2023-12-21T13:19:17.413867Z","iopub.status.idle":"2023-12-21T13:19:17.420090Z","shell.execute_reply.started":"2023-12-21T13:19:17.413831Z","shell.execute_reply":"2023-12-21T13:19:17.419009Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# # モデルの学習と予測\n\n# # モデルのパラメータを指定する\n# params = {'param1': 10, 'param2': 100}\n\n# # モデルを定義する\n# model = Model(params)\n\n# # 学習データに対してモデルを学習させる\n# model.fit(train_x, train_y)\n\n# # テストデータに対して予測結果を出力する\n# pred = model.predict(test_x)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T13:19:17.421349Z","iopub.execute_input":"2023-12-21T13:19:17.421685Z","iopub.status.idle":"2023-12-21T13:19:17.434051Z","shell.execute_reply.started":"2023-12-21T13:19:17.421649Z","shell.execute_reply":"2023-12-21T13:19:17.432991Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2023-12-21T13:19:17.435318Z","iopub.execute_input":"2023-12-21T13:19:17.436236Z","iopub.status.idle":"2023-12-21T13:19:17.444984Z","shell.execute_reply.started":"2023-12-21T13:19:17.436194Z","shell.execute_reply":"2023-12-21T13:19:17.443635Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"xgboost = XGBClassifier(random_state=42, max_depth=5)\nxgboost.fit(train_x, train_y)\n\nxgb_proba = xgboost.predict_proba(test_x)\n\nprobs = xgb_proba\n\nsubmission = pd.DataFrame({\n    'id': test_id,\n    'Status_C': np.round(probs[:, 0], 4),\n    'Status_CL': np.round(probs[:, 1], 4),\n    'Status_D': np.round(probs[:, 2], 4)\n})","metadata":{"execution":{"iopub.status.busy":"2023-12-21T13:19:17.446588Z","iopub.execute_input":"2023-12-21T13:19:17.447243Z","iopub.status.idle":"2023-12-21T13:19:18.221676Z","shell.execute_reply.started":"2023-12-21T13:19:17.447212Z","shell.execute_reply":"2023-12-21T13:19:18.220633Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2023-12-21T13:19:18.223059Z","iopub.execute_input":"2023-12-21T13:19:18.223741Z","iopub.status.idle":"2023-12-21T13:19:18.236489Z","shell.execute_reply.started":"2023-12-21T13:19:18.223708Z","shell.execute_reply":"2023-12-21T13:19:18.235718Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"         id  Status_C  Status_CL  Status_D\n0      7905    0.7070     0.0072    0.2857\n1      7906    0.5586     0.1322    0.3092\n2      7907    0.9956     0.0009    0.0034\n3      7908    0.0205     0.0004    0.9791\n4      7909    0.0715     0.0294    0.8991\n...     ...       ...        ...       ...\n5266  13171    0.0180     0.0117    0.9703\n5267  13172    0.0050     0.0005    0.9945\n5268  13173    0.0414     0.0011    0.9576\n5269  13174    0.0027     0.0020    0.9953\n5270  13175    0.9139     0.0048    0.0813\n\n[5271 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Status_C</th>\n      <th>Status_CL</th>\n      <th>Status_D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7905</td>\n      <td>0.7070</td>\n      <td>0.0072</td>\n      <td>0.2857</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7906</td>\n      <td>0.5586</td>\n      <td>0.1322</td>\n      <td>0.3092</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7907</td>\n      <td>0.9956</td>\n      <td>0.0009</td>\n      <td>0.0034</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7908</td>\n      <td>0.0205</td>\n      <td>0.0004</td>\n      <td>0.9791</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7909</td>\n      <td>0.0715</td>\n      <td>0.0294</td>\n      <td>0.8991</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5266</th>\n      <td>13171</td>\n      <td>0.0180</td>\n      <td>0.0117</td>\n      <td>0.9703</td>\n    </tr>\n    <tr>\n      <th>5267</th>\n      <td>13172</td>\n      <td>0.0050</td>\n      <td>0.0005</td>\n      <td>0.9945</td>\n    </tr>\n    <tr>\n      <th>5268</th>\n      <td>13173</td>\n      <td>0.0414</td>\n      <td>0.0011</td>\n      <td>0.9576</td>\n    </tr>\n    <tr>\n      <th>5269</th>\n      <td>13174</td>\n      <td>0.0027</td>\n      <td>0.0020</td>\n      <td>0.9953</td>\n    </tr>\n    <tr>\n      <th>5270</th>\n      <td>13175</td>\n      <td>0.9139</td>\n      <td>0.0048</td>\n      <td>0.0813</td>\n    </tr>\n  </tbody>\n</table>\n<p>5271 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T13:19:18.237546Z","iopub.execute_input":"2023-12-21T13:19:18.238378Z","iopub.status.idle":"2023-12-21T13:19:18.264661Z","shell.execute_reply.started":"2023-12-21T13:19:18.238349Z","shell.execute_reply":"2023-12-21T13:19:18.263574Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}